{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99256ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "folder = \"kfilter\"\n",
    "output_folder = \"output_videos\"\n",
    "results_json = \"conteo_resultados.json\"\n",
    "\n",
    "# Crear carpeta de salida si no existe\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "rest_of_videos: List[str] = [os.path.join(folder, video) for video in [\n",
    "    \"01-1.mp4\", \"02-1.mp4\", \"03-1.mp4\", \"04-1.mp4\", \"05-1.mp4\",\n",
    "    \"06-1.mp4\", \"07-1.mp4\", \"08-1.mp4\", \"09-1.mp4\", \"10-1.mp4\",\n",
    "    \"11-1.mp4\", \"12-1.mp4\", \"13-1.mp4\", \"14-1.mp4\", \"15-1.mp4\",\n",
    "    \"16-1.mp4\", \"17-1.mp4\", \"18-1.mp4\", \"19-1.mp4\", \"20-1.mp4\",\n",
    "    \"21-1.mp4\", \"22-1.mp4\", \"23-1.mp4\", \"24-1.mp4\", \"25-1.mp4\",\n",
    "    \"28-1.mp4\", \"29-1.mp4\", \"30-1.mp4\", \"31-1.mp4\", \"32-1.mp4\",\n",
    "    \"33-1.mp4\", \"34-1.mp4\", \"35-1.mp4\", \"36-1.mp4\", \"37-1.mp4\",\n",
    "    \"38-1.mp4\", \"39-1.mp4\", \"41-1.mp4\", \"42-1.mp4\", \"43-1.mp4\"\n",
    "]]\n",
    "\n",
    "# Variables globales para la configuración de línea\n",
    "line_points = []\n",
    "current_video_path = \"\"\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    \"\"\"Callback para capturar los puntos de la línea de conteo\"\"\"\n",
    "    global line_points\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if len(line_points) < 2:\n",
    "            line_points.append((x, y))\n",
    "            print(f\"Punto {len(line_points)} seleccionado: ({x}, {y})\")\n",
    "            if len(line_points) == 2:\n",
    "                print(\"Línea configurada. Presiona 'ENTER' para continuar o 'r' para reiniciar\")\n",
    "\n",
    "def configure_line(video_path: str) -> Tuple[Tuple[int, int], Tuple[int, int]]:\n",
    "    \"\"\"Permite al usuario configurar la línea de conteo para un video\"\"\"\n",
    "    global line_points\n",
    "    line_points = []\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        print(f\"Error al leer el video: {video_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Reducir tamaño si es muy grande\n",
    "    height, width = frame.shape[:2]\n",
    "    if width > 1280:\n",
    "        scale = 1280 / width\n",
    "        frame = cv2.resize(frame, (int(width * scale), int(height * scale)))\n",
    "    \n",
    "    window_name = f\"Configura la línea - {os.path.basename(video_path)}\"\n",
    "    cv2.namedWindow(window_name)\n",
    "    cv2.setMouseCallback(window_name, mouse_callback)\n",
    "    \n",
    "    print(f\"\\n--- Configurando: {os.path.basename(video_path)} ---\")\n",
    "    print(\"Haz clic en 2 puntos para definir la línea de conteo\")\n",
    "    print(\"Presiona 'r' para reiniciar, 'ENTER' para confirmar, 'q' para saltar video\")\n",
    "    \n",
    "    while True:\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        # Dibujar puntos y línea\n",
    "        for i, point in enumerate(line_points):\n",
    "            cv2.circle(display_frame, point, 5, (0, 255, 0), -1)\n",
    "            cv2.putText(display_frame, str(i+1), (point[0]+10, point[1]), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        if len(line_points) == 2:\n",
    "            cv2.line(display_frame, line_points[0], line_points[1], (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow(window_name, display_frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 13 and len(line_points) == 2:  # ENTER\n",
    "            break\n",
    "        elif key == ord('r'):  # Reiniciar\n",
    "            line_points = []\n",
    "            print(\"Línea reiniciada. Selecciona 2 puntos nuevamente\")\n",
    "        elif key == ord('q'):  # Saltar\n",
    "            cv2.destroyAllWindows()\n",
    "            return None\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return tuple(line_points)\n",
    "\n",
    "def point_above_line(point, line_start, line_end):\n",
    "    \"\"\"Determina si un punto está por encima de la línea (dirección del cruce)\"\"\"\n",
    "    x, y = point\n",
    "    x1, y1 = line_start\n",
    "    x2, y2 = line_end\n",
    "    \n",
    "    # Producto cruzado para determinar el lado\n",
    "    return (x2 - x1) * (y - y1) - (y2 - y1) * (x - x1) > 0\n",
    "\n",
    "def process_video(video_path: str, line: Tuple[Tuple[int, int], Tuple[int, int]]) -> int:\n",
    "    \"\"\"Procesa el video y cuenta los cruces de la línea\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Propiedades del video\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Configurar video de salida\n",
    "    output_path = os.path.join(output_folder, os.path.basename(video_path))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Sustracción de fondo\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "    \n",
    "    # Variables de conteo\n",
    "    count = 0\n",
    "    tracked_objects = {}\n",
    "    next_object_id = 0\n",
    "    \n",
    "    line_start, line_end = line\n",
    "    \n",
    "    print(f\"Procesando: {os.path.basename(video_path)}\")\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Detección de movimiento\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "        \n",
    "        # Limpieza de ruido\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        # Encontrar contornos\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        current_centroids = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 500:  # Filtrar objetos pequeños\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    current_centroids.append((cx, cy))\n",
    "        \n",
    "        # Tracking simple y detección de cruces\n",
    "        new_tracked = {}\n",
    "        for centroid in current_centroids:\n",
    "            matched = False\n",
    "            for obj_id, obj_data in tracked_objects.items():\n",
    "                prev_centroid = obj_data['centroid']\n",
    "                distance = ((centroid[0] - prev_centroid[0])**2 + (centroid[1] - prev_centroid[1])**2)**0.5\n",
    "                \n",
    "                if distance < 50:  # Umbral de matching\n",
    "                    # Verificar cruce de línea\n",
    "                    prev_side = point_above_line(prev_centroid, line_start, line_end)\n",
    "                    curr_side = point_above_line(centroid, line_start, line_end)\n",
    "                    \n",
    "                    if prev_side != curr_side and not obj_data['counted']:\n",
    "                        count += 1\n",
    "                        obj_data['counted'] = True\n",
    "                        print(f\"  Frame {frame_count}: ¡Cruce detectado! Total: {count}\")\n",
    "                    \n",
    "                    new_tracked[obj_id] = {'centroid': centroid, 'counted': obj_data['counted']}\n",
    "                    matched = True\n",
    "                    break\n",
    "            \n",
    "            if not matched:\n",
    "                new_tracked[next_object_id] = {'centroid': centroid, 'counted': False}\n",
    "                next_object_id += 1\n",
    "        \n",
    "        tracked_objects = new_tracked\n",
    "        \n",
    "        # Dibujar en el frame\n",
    "        cv2.line(frame, line_start, line_end, (0, 255, 0), 3)\n",
    "        cv2.putText(frame, f\"Conteo: {count}\", (10, 50), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)\n",
    "        \n",
    "        # Dibujar centroides\n",
    "        for obj_data in tracked_objects.values():\n",
    "            cv2.circle(frame, obj_data['centroid'], 5, (0, 0, 255), -1)\n",
    "        \n",
    "        out.write(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Conteo final: {count}\")\n",
    "    print(f\"Video guardado en: {output_path}\\n\")\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Procesar todos los videos\n",
    "results = {}\n",
    "\n",
    "for video_path in rest_of_videos:\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Video no encontrado: {video_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Configurar línea para este video\n",
    "    line = configure_line(video_path)\n",
    "    \n",
    "    if line is None:\n",
    "        print(f\"Video saltado: {os.path.basename(video_path)}\\n\")\n",
    "        continue\n",
    "    \n",
    "    # Procesar video\n",
    "    count = process_video(video_path, line)\n",
    "    \n",
    "    # Guardar resultado\n",
    "    video_name = os.path.basename(video_path)\n",
    "    results[video_name] = {\n",
    "        \"conteo\": count,\n",
    "        \"linea\": {\"inicio\": line[0], \"fin\": line[1]}\n",
    "    }\n",
    "\n",
    "# Guardar JSON con resultados\n",
    "with open(results_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Procesamiento completado!\")\n",
    "print(f\"Resultados guardados en: {results_json}\")\n",
    "print(f\"Videos procesados en: {output_folder}\")\n",
    "print(f\"{'='*50}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
